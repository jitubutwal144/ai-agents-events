### Discord channel
- https://discord.com/channels/1044870049908932638/1106636922840952902

### Topic: Fine Tuning Special (8th Sept, 2023, Friday, 19:00 to 20:00 CEST)
- There are several reasons why people are interested in fine-tuning for eg.
if you want domain-specific models
if you want to improve the performance on that particular task
if one wants to make the model smaller
basically use LLMs better - this would include prompting lets say
This is one event covering up three key approaches in fine-tuning your LLMs-
1) Lucas Meyer presenting Semantic Kernels
2) Harpreet Sahota presenting RAG
3) Chris Alexiuk presenting LORA
Each of the speakers will talk about the foundations before showcasing an actual implementation of the techniques.

### Links shared during the meeting
- Microsoft semantic kernel: https://links.meyerperin.com/sktour
- Hierarchical Agents: https://colab.research.google.com/drive/1qIb09SyuLeiwGy_FGcRcQpM78yQ2p0_3?usp=sharing
- Structured retrieval for large document sets: https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/dev_practices/production_rag.html#structured-retrieval-for-larger-document-sets
- Retrieval Augmentation Reduces Hallucination in Conversation: https://arxiv.org/pdf/2104.07567.pdf
- RAG/RAQA Blog: https://colab.research.google.com/drive/14VRXcGHu6u0R15AE8cjefERSgdszBYmW
- Instruct tune Llama2 with QLoRA: https://colab.research.google.com/drive/1d0JH7heSuEgVVWv5T4xE3dwS-BihuMGY#scrollTo=k6tPnThz1nGF

